---
# Model type and architecture
model_mode: aae                   # Model to use. ae:Autoencoder, aae:Adversarial AE, vae: Variational AE, bvae: Beta VAE
adv_training: true                # True if Discriminators are used. Otherwise, it will train only the Autoencoder model in the mode defined by model_mode
convolution: false                # Set true if you want to use CNN-based architecture. Else, it will use fully-connected layers.
conditional: true                 #

# Architecture-related params
dims:                             # Autoencoder architecture - This is for Encoder, and Decoder is symmetric to Encoder. Note that
  - 1024                          # Input dimension = number of features is added automatically, so it does not need to be defined here.
  - 512
  - 2
conv_dims:                        # Architecture for Encoder with convolutional layers
  - [ 1,  64, 4, 2, 1, 1]         # i=input channel, o=output channel, k = kernel, s = stride, p = padding, d = dilation
  - [64,  64, 4, 2, 1, 1]         # [i, o, k, s, p, d]
  - [64, 128, 4, 2, 1, 1]         # [i, o, k, s, p, d]
  - [128, 256, 4, 2, 1, 1]        # [i, o, k, s, p, d]
  - 128                           # Dimension of bottleneck layer
isBatchNorm: false                # Set True to use BatchNorm layer
isDropout: true                   # Set True to use Dropout layer

# Number of domains, & clusters/classes/cohorts
n_domains: 3                      # Number of domains (data sources) used.
n_cohorts: 4                      # Number of additional input features for discriminator of latent space when it is used as conditional discriminator
output_dim: 2                     # Classifier output dimension. For binary classification, use 2. For classification of domains, use == n_domains

# Parameters for VAE, and p-norm normalisation
beta: 1.0                         # Factor used for Beta-VAE model (Beta >1). Use <1 for better reconstruction/clustering
stddev: 1.0                       # Stddev used for sampling during re-parameterization in AE

# p-norm if z is normalised
normalize: false                   # If True, we do L2 normalization on latent variable
p_norm: 2                         # p-value used for normalization. p=2 for L2 norm, p=1 for L1 norm and so on.

# Parameters for training
dropout_rate: 0.2                 # Set dropout rate if Dropout is being used
learning_rate: 0.001              # Learning rate for training
epochs: 40                        # Number of epochs to use for training
batch_size: 32                    # Set batch size
nth_epoch: 5                      # Compute validation loss in every nth_epoch
scheduler: false                  # If True, turns on scheduler for learning rate.
noise: false                      # If True, adds Gaussian noise to the input (in fully connected Autoencoder).

# Whether to save files
save_files: false                 # If True, save translations between domains as csv files in 1_eval.py